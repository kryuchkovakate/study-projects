{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T16:51:49.656443Z",
          "iopub.status.busy": "2024-06-07T16:51:49.655233Z",
          "iopub.status.idle": "2024-06-07T16:52:05.573959Z",
          "shell.execute_reply": "2024-06-07T16:52:05.573147Z",
          "shell.execute_reply.started": "2024-06-07T16:51:49.656397Z"
        },
        "id": "7epjZ3RNqF95",
        "tags": [],
        "outputId": "fdcc7cd0-d7e0-42c6-d254-fb22f2444256"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader, Dataset\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.models as models\n",
        "import zipfile\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from pymystem3 import Mystem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T16:52:10.112421Z",
          "iopub.status.busy": "2024-06-07T16:52:10.111350Z",
          "iopub.status.idle": "2024-06-07T16:52:10.162382Z",
          "shell.execute_reply": "2024-06-07T16:52:10.161370Z",
          "shell.execute_reply.started": "2024-06-07T16:52:10.112375Z"
        },
        "tags": [],
        "id": "VQcwDhZ9pojj"
      },
      "outputs": [],
      "source": [
        "# pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:14:58.757771Z",
          "iopub.status.busy": "2024-06-07T17:14:58.756686Z",
          "iopub.status.idle": "2024-06-07T17:14:58.900303Z",
          "shell.execute_reply": "2024-06-07T17:14:58.899548Z",
          "shell.execute_reply.started": "2024-06-07T17:14:58.757725Z"
        },
        "id": "F4RK2PHMqYor",
        "tags": []
      },
      "outputs": [],
      "source": [
        "comm = pd.read_csv('train.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:14:59.669673Z",
          "iopub.status.busy": "2024-06-07T17:14:59.668422Z",
          "iopub.status.idle": "2024-06-07T17:14:59.724991Z",
          "shell.execute_reply": "2024-06-07T17:14:59.724264Z",
          "shell.execute_reply.started": "2024-06-07T17:14:59.669628Z"
        },
        "tags": [],
        "id": "747lPB8vpojk"
      },
      "outputs": [],
      "source": [
        "comm_test = pd.read_csv('test.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-06-07T17:15:00.392198Z",
          "iopub.status.busy": "2024-06-07T17:15:00.391424Z",
          "iopub.status.idle": "2024-06-07T17:15:00.449444Z",
          "shell.execute_reply": "2024-06-07T17:15:00.448592Z",
          "shell.execute_reply.started": "2024-06-07T17:15:00.392157Z"
        },
        "id": "VDSleee4qncv",
        "outputId": "c1b2e29f-3141-43f1-a689-36006a8c7246",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "      <td>Или эти программисты, зарабатывающие 3кк с, вс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15001</td>\n",
              "      <td>0,3 с коррекцией, т.е в очках или линзах.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15002</td>\n",
              "      <td>...\\n\\nДа, здесь все идет. Это моя страница об...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15003</td>\n",
              "      <td>Да. Но отчасти в этом есть вина и самой теслы....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15004</td>\n",
              "      <td>нужен баланс между труд отдых зачем? бывали сл...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                            comment\n",
              "0  15000  Или эти программисты, зарабатывающие 3кк с, вс...\n",
              "1  15001        0,3 с коррекцией, т.е в очках или линзах.\\n\n",
              "2  15002  ...\\n\\nДа, здесь все идет. Это моя страница об...\n",
              "3  15003  Да. Но отчасти в этом есть вина и самой теслы....\n",
              "4  15004  нужен баланс между труд отдых зачем? бывали сл..."
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comm_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-07T17:15:01.117290Z",
          "iopub.status.busy": "2024-06-07T17:15:01.116280Z",
          "iopub.status.idle": "2024-06-07T17:15:01.230737Z",
          "shell.execute_reply": "2024-06-07T17:15:01.229829Z",
          "shell.execute_reply.started": "2024-06-07T17:15:01.117247Z"
        },
        "id": "EueuLM71H9zA",
        "outputId": "24c4a49f-15f2-40f7-a3f3-3aa2921eb05b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   id       15000 non-null  int64 \n",
            " 1   comment  15000 non-null  object\n",
            " 2   toxic    15000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 351.7+ KB\n"
          ]
        }
      ],
      "source": [
        "comm.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-07T17:15:01.857340Z",
          "iopub.status.busy": "2024-06-07T17:15:01.856589Z",
          "iopub.status.idle": "2024-06-07T17:15:01.916239Z",
          "shell.execute_reply": "2024-06-07T17:15:01.915428Z",
          "shell.execute_reply.started": "2024-06-07T17:15:01.857297Z"
        },
        "id": "28tdv2WcIZ4Q",
        "outputId": "02fde0e4-aeef-4af8-aa23-2ea48c8dca40",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comm.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "execution": {
          "iopub.execute_input": "2024-06-07T17:15:02.623225Z",
          "iopub.status.busy": "2024-06-07T17:15:02.622398Z",
          "iopub.status.idle": "2024-06-07T17:15:26.877729Z",
          "shell.execute_reply": "2024-06-07T17:15:26.876866Z",
          "shell.execute_reply.started": "2024-06-07T17:15:02.623181Z"
        },
        "id": "1dbuRRNSdYvW",
        "outputId": "8d459cf0-bb84-409d-b71a-b885c77b411f",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[бесполезно, пытаться, доносить, человек, кома...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[свинья, уметь, читать]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[червепидорский, страна, парашный, конфедераци...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[это, зайти, сюда, специально, информация, ниг...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[дополнение, дентрен, чилийский, грязь, которы...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>14995</td>\n",
              "      <td>[обращать, внимание, дополнение, категория, по...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>14996</td>\n",
              "      <td>[борцовский, арена, собираться, заключать, сде...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>14997</td>\n",
              "      <td>[заниматься, свинособака, бесплатно, секс, нед...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>14998</td>\n",
              "      <td>[хуйло, почему, считать, постить, аватара, это...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>14999</td>\n",
              "      <td>[самый, дело, жара, вредный, снижать, эффектив...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                            comment  toxic\n",
              "0          0  [бесполезно, пытаться, доносить, человек, кома...      0\n",
              "1          1                            [свинья, уметь, читать]      1\n",
              "2          2  [червепидорский, страна, парашный, конфедераци...      1\n",
              "3          3  [это, зайти, сюда, специально, информация, ниг...      1\n",
              "4          4  [дополнение, дентрен, чилийский, грязь, которы...      0\n",
              "...      ...                                                ...    ...\n",
              "14995  14995  [обращать, внимание, дополнение, категория, по...      0\n",
              "14996  14996  [борцовский, арена, собираться, заключать, сде...      0\n",
              "14997  14997  [заниматься, свинособака, бесплатно, секс, нед...      1\n",
              "14998  14998  [хуйло, почему, считать, постить, аватара, это...      1\n",
              "14999  14999  [самый, дело, жара, вредный, снижать, эффектив...      0\n",
              "\n",
              "[15000 rows x 3 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "mystem = Mystem()\n",
        "def prep_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'[^а-яё]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    lemmatized_text = ' '.join(mystem.lemmatize(text))\n",
        "    tokens = [word for word in lemmatized_text.split() if word not in stop_words]\n",
        "    tokens = list(dict.fromkeys(tokens))\n",
        "    return tokens\n",
        "comm['comment'] = comm['comment'].apply(prep_text)\n",
        "comm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:15:55.272310Z",
          "iopub.status.busy": "2024-06-07T17:15:55.271195Z",
          "iopub.status.idle": "2024-06-07T17:16:03.800644Z",
          "shell.execute_reply": "2024-06-07T17:16:03.799885Z",
          "shell.execute_reply.started": "2024-06-07T17:15:55.272274Z"
        },
        "id": "GARgZN3rpojn"
      },
      "outputs": [],
      "source": [
        "comm_test['comment'] = comm_test['comment'].apply(prep_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:16:22.750940Z",
          "iopub.status.busy": "2024-06-07T17:16:22.749822Z",
          "iopub.status.idle": "2024-06-07T17:16:22.779829Z",
          "shell.execute_reply": "2024-06-07T17:16:22.779043Z",
          "shell.execute_reply.started": "2024-06-07T17:16:22.750892Z"
        },
        "id": "MUuNk2zNIuZf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "comm_data = comm.drop(['id','toxic'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:16:23.648388Z",
          "iopub.status.busy": "2024-06-07T17:16:23.647262Z",
          "iopub.status.idle": "2024-06-07T17:16:23.663626Z",
          "shell.execute_reply": "2024-06-07T17:16:23.662772Z",
          "shell.execute_reply.started": "2024-06-07T17:16:23.648344Z"
        },
        "id": "FGxDU8QwJ8Ej",
        "tags": []
      },
      "outputs": [],
      "source": [
        "comm_target = comm.drop(['id','comment'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:16:28.130914Z",
          "iopub.status.busy": "2024-06-07T17:16:28.129886Z",
          "iopub.status.idle": "2024-06-07T17:16:28.155535Z",
          "shell.execute_reply": "2024-06-07T17:16:28.154699Z",
          "shell.execute_reply.started": "2024-06-07T17:16:28.130870Z"
        },
        "id": "4VV0nHQrKRcu",
        "tags": []
      },
      "outputs": [],
      "source": [
        "comm_data_train, comm_data_test, comm_target_train, comm_target_test = train_test_split(comm_data, comm_target, test_size=0.2, random_state=42)\n",
        "comm_data_val, comm_data_test, comm_target_val, comm_target_test = train_test_split(comm_data_test, comm_target_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:16:40.676879Z",
          "iopub.status.busy": "2024-06-07T17:16:40.675836Z",
          "iopub.status.idle": "2024-06-07T17:16:40.703423Z",
          "shell.execute_reply": "2024-06-07T17:16:40.702500Z",
          "shell.execute_reply.started": "2024-06-07T17:16:40.676834Z"
        },
        "id": "g-nfXHHk-7GJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class CommentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts.iloc[idx])\n",
        "        label = self.labels.iloc[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:18:07.901889Z",
          "iopub.status.busy": "2024-06-07T17:18:07.900738Z",
          "iopub.status.idle": "2024-06-07T17:18:08.453727Z",
          "shell.execute_reply": "2024-06-07T17:18:08.452926Z",
          "shell.execute_reply.started": "2024-06-07T17:18:07.901842Z"
        },
        "id": "cIpQwTvHbE7b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
        "max_len = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:18:09.664017Z",
          "iopub.status.busy": "2024-06-07T17:18:09.663110Z",
          "iopub.status.idle": "2024-06-07T17:18:09.699982Z",
          "shell.execute_reply": "2024-06-07T17:18:09.699037Z",
          "shell.execute_reply.started": "2024-06-07T17:18:09.663975Z"
        },
        "id": "eBhxFffZbE9y",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_dataset = CommentDataset(comm_data_train['comment'], comm_target_train, tokenizer, max_len)\n",
        "val_dataset = CommentDataset(comm_data_val['comment'], comm_target_val, tokenizer, max_len)\n",
        "test_dataset = CommentDataset(comm_data_test['comment'], comm_target_test, tokenizer, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:19:11.125426Z",
          "iopub.status.busy": "2024-06-07T17:19:11.124315Z",
          "iopub.status.idle": "2024-06-07T17:19:11.145416Z",
          "shell.execute_reply": "2024-06-07T17:19:11.144396Z",
          "shell.execute_reply.started": "2024-06-07T17:19:11.125383Z"
        },
        "tags": [],
        "id": "NS0AAM0lpojp"
      },
      "outputs": [],
      "source": [
        "test = CommentDataset(comm_test['comment'], comm_test['id'],tokenizer, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:19:14.342859Z",
          "iopub.status.busy": "2024-06-07T17:19:14.341727Z",
          "iopub.status.idle": "2024-06-07T17:19:14.378608Z",
          "shell.execute_reply": "2024-06-07T17:19:14.377811Z",
          "shell.execute_reply.started": "2024-06-07T17:19:14.342814Z"
        },
        "id": "tP1J9QD3bFDr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:19:42.197022Z",
          "iopub.status.busy": "2024-06-07T17:19:42.195969Z",
          "iopub.status.idle": "2024-06-07T17:19:42.211419Z",
          "shell.execute_reply": "2024-06-07T17:19:42.210611Z",
          "shell.execute_reply.started": "2024-06-07T17:19:42.196973Z"
        },
        "id": "6q2gLQhfpojp"
      },
      "outputs": [],
      "source": [
        "test = DataLoader(test, batch_size=16, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T16:52:40.702560Z",
          "iopub.status.busy": "2024-06-07T16:52:40.701357Z",
          "iopub.status.idle": "2024-06-07T17:06:22.528150Z",
          "shell.execute_reply": "2024-06-07T17:06:22.527307Z",
          "shell.execute_reply.started": "2024-06-07T16:52:40.702504Z"
        },
        "id": "2ZsTJxDue16h",
        "tags": [],
        "outputId": "034dc63d-36e9-4257-d5f5-49bf29b9bbe6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jupyter/.local/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.022120505399846783 Train accuracy: 10.2845\n",
            "Val loss: 0.015840234244863194 Val accuracy: 9.918666666666667\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train loss: 0.015173710732487961 Train accuracy: 10.200333333333333\n",
            "Val loss: 0.01801094836369157 Val accuracy: 9.790666666666667\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train loss: 0.011007535487180576 Train accuracy: 10.182833333333333\n",
            "Val loss: 0.020808576577653486 Val accuracy: 9.966666666666667\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"DeepPavlov/rubert-base-cased\", num_labels=2)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "\n",
        "def train_epoch(model, data_loader, optimizer, device):\n",
        "    model = model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        total_examples += labels.size(0)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return total_loss / total_examples, correct_predictions.double() / total_examples\n",
        "\n",
        "def eval_model(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            total_examples += labels.size(0)\n",
        "\n",
        "    return total_loss / total_examples, correct_predictions.double() / total_examples\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, device)\n",
        "    print(f'Train loss: {train_loss} Train accuracy: {train_acc}')\n",
        "\n",
        "    val_loss, val_acc = eval_model(model, val_loader, device)\n",
        "    print(f'Val loss: {val_loss} Val accuracy: {val_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:19:53.270140Z",
          "iopub.status.busy": "2024-06-07T17:19:53.268803Z",
          "iopub.status.idle": "2024-06-07T17:19:53.290300Z",
          "shell.execute_reply": "2024-06-07T17:19:53.289516Z",
          "shell.execute_reply.started": "2024-06-07T17:19:53.270092Z"
        },
        "id": "zz3KOkeAe18m",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def predict_model(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "    predictions = []\n",
        "    ids = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            ids.extend(labels.cpu().numpy())\n",
        "\n",
        "    return predictions, ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:20:11.907675Z",
          "iopub.status.busy": "2024-06-07T17:20:11.906624Z",
          "iopub.status.idle": "2024-06-07T17:20:46.972186Z",
          "shell.execute_reply": "2024-06-07T17:20:46.971312Z",
          "shell.execute_reply.started": "2024-06-07T17:20:11.907632Z"
        },
        "id": "E9VakBuYe1_5"
      },
      "outputs": [],
      "source": [
        "predictions, ids = predict_model(model, test, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:30:49.368333Z",
          "iopub.status.busy": "2024-06-07T17:30:49.367252Z",
          "iopub.status.idle": "2024-06-07T17:30:49.416490Z",
          "shell.execute_reply": "2024-06-07T17:30:49.415644Z",
          "shell.execute_reply.started": "2024-06-07T17:30:49.368284Z"
        },
        "id": "O_XhtN9cevwX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame({'ID' : ids,'prediction': predictions})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:30:50.726894Z",
          "iopub.status.busy": "2024-06-07T17:30:50.725786Z",
          "iopub.status.idle": "2024-06-07T17:30:50.759739Z",
          "shell.execute_reply": "2024-06-07T17:30:50.758856Z",
          "shell.execute_reply.started": "2024-06-07T17:30:50.726850Z"
        },
        "tags": [],
        "id": "yc9saZvnpojq",
        "outputId": "9fe5c4bb-f3a4-425b-e82e-96fa72d19d92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15001</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5407</th>\n",
              "      <td>20407</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408</th>\n",
              "      <td>20408</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5409</th>\n",
              "      <td>20409</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5410</th>\n",
              "      <td>20410</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5411</th>\n",
              "      <td>20411</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5412 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  prediction\n",
              "0     15000           0\n",
              "1     15001           0\n",
              "2     15002           1\n",
              "3     15003           0\n",
              "4     15004           0\n",
              "...     ...         ...\n",
              "5407  20407           0\n",
              "5408  20408           0\n",
              "5409  20409           0\n",
              "5410  20410           0\n",
              "5411  20411           0\n",
              "\n",
              "[5412 rows x 2 columns]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-07T17:31:09.979919Z",
          "iopub.status.busy": "2024-06-07T17:31:09.978702Z",
          "iopub.status.idle": "2024-06-07T17:31:10.061383Z",
          "shell.execute_reply": "2024-06-07T17:31:10.060565Z",
          "shell.execute_reply.started": "2024-06-07T17:31:09.979872Z"
        },
        "tags": [],
        "id": "6-H-HrwMpojr"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv('saaample.csv',index = False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DataSphere Kernel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}